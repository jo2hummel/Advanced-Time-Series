{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Assignment 3\n",
    "Matriculation Nr: 01/1152810\n",
    "\n",
    "Other group members: 1151277, 919755, 1151248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "\n",
    "from statsmodels.tsa.api import VAR"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read Appendix D in Lutkepohl (2005). Write a function that implements a residual bootstrap for a VAR(p) with intercept and returns the bootstrap standard errors of the VAR coefficients in B.†\n",
    "\n",
    "The function should take\n",
    "- a T + p × K matrix of observations on yt,\n",
    "- the lag length p,\n",
    "- and the number of bootstrap replications R as input."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def Z_matrix(y: np.array, p: int, c: int):\n",
    "    \"\"\"Calculate the Z-matrix for a given input\n",
    "\n",
    "    Args:\n",
    "        y (np.array): input with all the data of shape (T + p) × K\n",
    "        p (int): lags\n",
    "        c (int): intercept yes=1, no=0\n",
    "\n",
    "    Returns:\n",
    "        (np.array): Z-matrix for given input\n",
    "    \"\"\"\n",
    "\n",
    "    y = y.T\n",
    "\n",
    "    #determine matrix dimensions:\n",
    "    T = y.shape[1] - p\n",
    "    K = y.shape[0]\n",
    "\n",
    "    # build Z-matrix\n",
    "    if c==1:\n",
    "        Z = np.ones((1, T+p), dtype=float)\n",
    "\n",
    "    # 1b stacked lagged data\n",
    "    for i in range(p):\n",
    "        #add i columns of leading zeros (EDIT: empty, comp cost lower) to ktpmat\n",
    "        zeros = np.zeros((K, i), dtype=float)\n",
    "        zerostack = np.hstack((zeros, y[:,:(T+p-i)]))\n",
    "        # vertically stack this to Z\n",
    "        Z = np.vstack((Z, zerostack))\n",
    "\n",
    "    # cutting of leading p columns and retrieving Z\n",
    "    Z = Z[:, p-1:-1]\n",
    "\n",
    "    return Z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def B_matrix(y: np.array, p: int, c: int):\n",
    "    \"\"\"Calculates the B matrix with the estimated coefficients\n",
    "\n",
    "    Args:\n",
    "        y (np.array): input with all the data of shape (T + p) × K\n",
    "        p (int): lags\n",
    "        c (int): intercept yes=1, no=0\n",
    "\n",
    "    Returns:\n",
    "        _type_: B = matrix with estimated coefficients; Z=Z-matrix; resids=residual-matrix, sigma_u=covariance matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # get Z-matrix from function above\n",
    "    Z = Z_matrix(y, p, c)\n",
    "\n",
    "    y = y.T # transpose y\n",
    "    y = y[:,p:] # first p observations are lost as we need prior lags for estimation\n",
    "    K = y.shape[0] # number of variables\n",
    "    T = y.shape[1] # number of observations\n",
    "\n",
    "    # calculate B\n",
    "    B = y @ Z.T @ np.linalg.inv((Z@Z.T))\n",
    "\n",
    "    resids = y-(B@Z)\n",
    "\n",
    "    # calculate sigma_u (covariance matrix)\n",
    "    sigma_u = (1/(T-K*p-1))*resids@resids.T\n",
    "\n",
    "    return B, Z, resids, sigma_u"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "def resid_bootstrap(Tpkmat, p, R):\n",
    "    '''\n",
    "    :param Tpkmat: a T + p × K matrix of observations on yt,\n",
    "    :param p: the lag length p,\n",
    "    :param R: and the number of bootstrap replications R as input.\n",
    "    :return: returns the bootstrap standard errors of the VAR coefficients in B\n",
    "    '''\n",
    "\n",
    "    y = Tpkmat.T # transpose input matrix to K x (T+p)\n",
    "    T = y.shape[1] - p # get T (number of observations)\n",
    "    K = y.shape[0]\n",
    "\n",
    "    '''\n",
    "    Description from Lütkepohl, appendix D, page 709\n",
    "    (1) The parameters of the model under consideration are estimated. Let uthat, t = 1, . . . , T, be the estimation residuals.\n",
    "    '''\n",
    "\n",
    "    B, Z, resids, sigma_u = B_matrix(Tpkmat, p, c=1)\n",
    "\n",
    "    '''\n",
    "    (2) Centered residuals are computed (usual average).\n",
    "\n",
    "    Bootstrap residuals u∗1, . . . , u∗T are then obtained by randomly drawing with replacement from the centered residuals.\n",
    "    '''\n",
    "    uthatbar = np.sum(resids, axis=1)/T\n",
    "    uthatcenterded = resids - uthatbar.T.reshape(K, 1)\n",
    "\n",
    "    '''\n",
    "    (3) Bootstrap time series are computed recursively [...]where the same initial values may be used for each generated series, (y∗ −p+1, . . . , y∗0) = (y−p+1, . . . , y0).\n",
    "    '''\n",
    "    # I assume this part is wrong. We probably have to implement methods from appendix D1 (page 707) here instead of just adding the draws to our yhat\n",
    "\n",
    "    yhat = B@Z\n",
    "\n",
    "    # assuming we are sampling as many t as before (i.e. 189)? We will nevertheless not have any presample values anymore due to construction of Z. (i.e. new t will be t_old-p (because presample values are assumed in our B_matrix function)).\n",
    "    B_bs_list = np.empty((K, K*p+1))\n",
    "\n",
    "    for i in range(R):\n",
    "        draws = np.random.randint(0, T, T)\n",
    "        yhatbs = yhat + uthatcenterded[:,draws]\n",
    "\n",
    "        '''\n",
    "        (4) Based on the bootstrap time series, the parameters A1, . . . ,Ap are reestimated.\n",
    "        '''\n",
    "        B_bs, _, resids, sigma_u = B_matrix(yhatbs.T, p, c=1)\n",
    "        # stacking samples along axis 2\n",
    "        B_bs_list = np.dstack((B_bs_list, B_bs))\n",
    "\n",
    "        #re-calculating yhat with new estimates of B based on sample\n",
    "        yhat = B_bs@Z\n",
    "\n",
    "    '''\n",
    "    From assignment: †Use the standard deviation over the R bootstrap VAR estimates as a bootstrap standard error.\n",
    "    '''\n",
    "\n",
    "    Bbar_bs_list = np.mean(B_bs_list, axis = 2)\n",
    "    deviation = B_bs_list - Bbar_bs_list[:, :, None]\n",
    "    deviation_squared = deviation**2\n",
    "    sd = np.sqrt(np.sum(deviation_squared, axis=2)/(R-1))\n",
    "    se = sd/np.sqrt(R)\n",
    "\n",
    "    return se"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "# read in data\n",
    "awm = pd.read_csv(\"awm19up18.csv\")\n",
    "awm.rename(columns={awm.columns[0]: \"Q\" }, inplace = True)\n",
    "\n",
    "of_interest = [\"Q\", \"YER\", \"ITR\", \"LTN\", \"STN\"]\n",
    "awm = awm[awm.columns.intersection(of_interest)]\n",
    "awm.set_index('Q', inplace=True)\n",
    "\n",
    "# calculate logs and first differences and assign names accordingly\n",
    "awm[\"YER_log\"] = np.log(awm['YER'])\n",
    "awm[\"ITR_log\"] = np.log(awm['ITR'])\n",
    "\n",
    "awm[\"d_lgdp\"] = awm[\"YER_log\"].diff()\n",
    "awm[\"d_invest\"] = awm[\"ITR_log\"].diff()\n",
    "\n",
    "awm[\"d_lgdp\"] = awm[\"d_lgdp\"] * 400\n",
    "awm[\"d_invest\"] = awm[\"d_invest\"] * 400\n",
    "\n",
    "awm[\"d_R\"] = awm[\"LTN\"].diff()\n",
    "awm[\"d_r\"] = awm[\"STN\"].diff()\n",
    "\n",
    "awm.dropna(inplace=True)\n",
    "\n",
    "# get the input for our function\n",
    "y_t = np.array(awm[[\"d_lgdp\", \"d_invest\", \"d_R\", \"d_r\"]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "B, Z, resids, sigma_u = B_matrix(y_t, p=2, c=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "se = resid_bootstrap(y_t, 2, R=499)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.19991990e-01  4.41893745e-01 -3.09516135e-02  3.53840313e-01\n",
      "   2.80812932e-01  1.40348551e-01  2.89658568e-02 -6.61782716e-01\n",
      "  -6.99814626e-01]\n",
      " [-1.00607134e+00  1.20312057e+00 -2.28829643e-01 -1.26631209e+00\n",
      "   6.99606104e-01 -5.17309344e-02  2.41250166e-01 -1.21968589e+00\n",
      "  -1.57970603e+00]\n",
      " [-6.57473325e-02  1.20603459e-02  1.78784492e-04  5.15582681e-01\n",
      "   3.78561218e-02  1.32232293e-02 -5.88137520e-03 -2.20154123e-01\n",
      "   7.06111408e-02]\n",
      " [-2.43278598e-01  7.28410851e-02 -7.47895590e-03  4.22382718e-01\n",
      "   2.78528354e-01  3.87124972e-02 -2.40842053e-03 -2.89226900e-01\n",
      "  -7.25841414e-02]] [[0.83667181 2.72854121 3.01719155 0.02614192 0.09290543 2.42179127\n",
      "  2.91557032 0.05330722 0.04738715]\n",
      " [0.90550665 3.36761351 3.01048254 0.07428419 0.13897989 2.63615086\n",
      "  5.41161893 0.11883483 0.11323821]\n",
      " [0.08156234 0.04978427 0.12829088 0.02807889 0.03305658 0.04137488\n",
      "  0.07066681 0.00895616 0.02202074]\n",
      " [0.13829864 0.22517133 0.4063585  0.03499647 0.07121358 0.18387271\n",
      "  0.3450008  0.00991092 0.02509527]]\n"
     ]
    }
   ],
   "source": [
    "## does our B_matrix function return SDs?\n",
    "print(B, se)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write a Python function that simulates time series data from a K-dimensional VAR(2) process yt = A1yt−1 + A2yt−2 + ut, where the innovations ut are drawn from a multivariate normal distribution with mean zero and covariance matrix Σu. Use y−1 = y0 = 0 as starting values, where 0 is a K × 1 vector of zeros, generate time series of length T + 50 and discard the first 50 observations, such that you have available time series of total length equal to T.\n",
    "\n",
    "Your function should take A1, A2, Σu and T as an input and should return a T × K matrix\n",
    "of observations on yt."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "def var2sim(A1, A2, sigma_u, T):\n",
    "    '''\n",
    "    :param A1:\n",
    "    :param A2:\n",
    "    :param sigma_u:\n",
    "    :param T:\n",
    "    :return:\n",
    "    '''\n",
    "    p= 2\n",
    "    K = int(sigma_u.shape[0]/p)\n",
    "\n",
    "    # method from page 708\n",
    "    A = np.hstack((np.identity((K*p-1)), np.zeros((K*p-1, 1), dtype=float)))\n",
    "    A = np.vstack((np.hstack((A1, A2)), A))\n",
    "\n",
    "\n",
    "    # generate time-series of length T+50\n",
    "\n",
    "    # discard first 50 observations\n",
    "\n",
    "\n",
    "    return A"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.12155007, 0.37876129, 0.7010412 , 0.16732411, 0.56435442,\n        0.12681757],\n       [0.79998586, 0.45464893, 0.4459351 , 0.20893036, 0.63115058,\n        0.14632153],\n       [0.31541566, 0.86208548, 0.75614209, 0.48558215, 0.07879846,\n        0.86614755],\n       [1.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        ],\n       [0.        , 1.        , 0.        , 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 1.        , 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , 1.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , 0.        , 1.        ,\n        0.        ]])"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1 = np.random.rand(3, 3)\n",
    "A2 = np.random.rand(3, 3)\n",
    "sigma_u = np.random.rand(6, 6)\n",
    "T = 100\n",
    "var2sim(A1, A2, sigma_u, T)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "(5, 1)"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 3\n",
    "p=2\n",
    "np.identity(K*p-1)\n",
    "np.zeros((K*p-1, 1))\n",
    "np.zeros(((K*p-1), 1)).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# remaining code from assignment 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def granger(y: np.array, p: int, dummy_vec: list, c=1):\n",
    "    \"\"\"Performs the Granger Causality Test on a given set of variables\n",
    "\n",
    "    Args:\n",
    "        y (np.array): input with all the data of shape (T + p) × K\n",
    "        p (int): lags\n",
    "        dummy_vec (list): list with causing (1) and caused (0) signs\n",
    "        c (int): intercept yes=1, no=0 \n",
    "\n",
    "    Returns:\n",
    "        _type_: Wald- and F-statistic together with implied p-values\n",
    "    \"\"\"\n",
    "    \n",
    "    y = y.T # transpose y\n",
    "    n_cause = sum(dummy_vec) # number of causing variables = 1's in the list\n",
    "    n_caused = len(dummy_vec) - n_cause # number of caused variables\n",
    "       \n",
    "    # arrange in right order (first cause variables, then caused variables)\n",
    "    cause = []\n",
    "    caused = []\n",
    "    for i, n in enumerate(dummy_vec):\n",
    "        if n == 1:\n",
    "            cause.append(y[i])\n",
    "        else:\n",
    "            caused.append(y[i])\n",
    "    \n",
    "    cause = np.column_stack(cause)\n",
    "    caused = np.column_stack(caused)\n",
    "    y = np.concatenate((cause, caused), axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # get B matrix, Z, and covariance matrix from above function\n",
    "    K = y.shape[1]  # number of variables\n",
    "    T = np.size(y, 0) - p\n",
    "    B, Z, sigma_u = B_matrix(y, p, c) # return all three\n",
    "    \n",
    "    # get indices for positions that should be checked\n",
    "    relevant_parts = []\n",
    "    for p_ in range(p):\n",
    "        for a_v in range(n_cause):\n",
    "            for p_v in range(n_caused):\n",
    "                relevant_parts.append(K*c + n_cause + p_v + a_v*K + p_*(K**2))\n",
    "   \n",
    "    # vectorize B matrix (F=column-wise)\n",
    "    vec_B = B.flatten(order=\"F\").T\n",
    "    \n",
    "    # initialize C with zeros only\n",
    "    C = np.zeros([len(relevant_parts), len(vec_B)])\n",
    "    \n",
    "    \n",
    "    # add 1 at relevant parts\n",
    "    for i, num in enumerate(relevant_parts):\n",
    "        C[i, num] = 1\n",
    "    \n",
    "    # calculate lambdas\n",
    "    lambda_w = (C@vec_B).T @ np.linalg.inv(C @ np.kron(np.linalg.inv(Z@Z.T), sigma_u) @ C.T) @ C@vec_B\n",
    "    lambda_f = lambda_w/len(relevant_parts)\n",
    "    \n",
    "    # degrees of freedom\n",
    "    df_chi2 = len(relevant_parts)\n",
    "    df_fn = len(relevant_parts)\n",
    "    df_fd = T*K-((K**2)*p)-K\n",
    "    \n",
    "    # p_values\n",
    "    p_val_chi2 = round(abs(1-st.chi2.cdf(lambda_w, df_chi2)), 4)\n",
    "    p_val_f = round(abs(1-st.f.cdf(lambda_f, df_fn, df_fd)), 4)\n",
    "    \n",
    "    # ftest degrees freedom\n",
    "    df_fd = (len(relevant_parts),T*K-((K**2)*p)-K)\n",
    "\n",
    "    return lambda_w, p_val_chi2, df_fn, lambda_f, p_val_f, df_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Granger Causality\n",
    "ts_w, p_w, df_w, ts_f, p_f, df_f = granger(y_t, 2, [0, 0, 1, 1], 1)\n",
    "print(f'ts_w: {ts_w}, \\np_w: {p_w}, \\ndf_w: {df_w}, \\nts_f: {ts_f}, \\np_f: {p_f}, \\ndf_f: {df_f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check with Built-In Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check result with statsmodels VAR module\n",
    "model = VAR(awm[[\"d_lgdp\", \"d_invest\", \"d_R\", \"d_r\"]])\n",
    "results = model.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wald test\n",
    "granger_stat_wald = results.test_causality([\"d_lgdp\", \"d_invest\"],['d_R', \"d_r\"], kind='wald')\n",
    "granger_stat_wald.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# F-test\n",
    "granger_stat_f = results.test_causality([\"d_lgdp\", \"d_invest\"],['d_R', \"d_r\"], kind='f')\n",
    "granger_stat_f.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f53b217d8430526303bffcd87b390d5c67e67390f11595101f60a03768747934"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}